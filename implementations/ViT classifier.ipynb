{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51d70fa1-87e6-438a-99c1-1e5b1d54a387",
   "metadata": {},
   "source": [
    "Vision Transformer Classifier\n",
    "---\n",
    "\n",
    "In this notebook, we are going to use the [ViT backbone](https://github.com/romaingrx/relax/blob/master/relax/models/ViT.py) implemented in the [relax](https://github.com/romaingrx/relax/) package to classify the MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f905c242-6eab-471a-8142-8fbe171b118c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 20:19:07.844841: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 20:19:07.990191: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-22 20:19:08.585791: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu\n",
      "2022-11-22 20:19:08.585873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu\n",
      "2022-11-22 20:19:08.585879: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-22 20:19:09.614738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 20:19:09.646902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 20:19:09.647206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 20:19:10.042949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "# Ensure TF does not see GPU and grab all GPU memory.\n",
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import jax\n",
    "import einops\n",
    "import optax\n",
    "import haiku as hk\n",
    "from relax import Trainer, TrainingConfig\n",
    "from relax.models import ViT as ViTBackbone\n",
    "\n",
    "from typing import Optional, Union, Sequence, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "def ds_to_array(ds):\n",
    "    itr = (\n",
    "            ds\n",
    "            .map(lambda d: (d['image'] / 255, d['label']))\n",
    "            .as_numpy_iterator()\n",
    "            )\n",
    "    return jax.device_put(list(itr))\n",
    "\n",
    "train_ds, test_ds = tfds.load(\"mnist\", split=[\"train[:80%]\", \"test\"], batch_size=128)\n",
    "x = ds_to_array(train_ds)\n",
    "x_test = ds_to_array(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec436c54-46d5-42d8-8765-06acc5b28730",
   "metadata": {},
   "source": [
    "Let's define the ViT as the ViT backbone (basically just a the patch encoding + transformer encoder) on which we add the classification layers (one hidden and the final one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b9f8d6-8ffc-4c7d-90d8-74910e750aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(ViTBackbone):\n",
    "    def __init__(self, n_classes: int, *args, n_hidden: int = 512, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.n_hidden = n_hidden\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        latent = super().__call__(x)\n",
    "        flattened_latent = einops.rearrange(latent, 'b ... -> b (...)')\n",
    "        \n",
    "        z = hk.Linear(self.n_hidden, name=\"hidden_clf\")(flattened_latent)\n",
    "        z = jax.nn.relu(z)\n",
    "        \n",
    "        logits = hk.Linear(self.n_classes, name=\"clf\")(z)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a948fa-d995-4724-9211-28039fb762b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@hk.transform\n",
    "def model(x):\n",
    "    logits = ViT(10, (8, 8), 64)(x)\n",
    "    return logits\n",
    "\n",
    "def loss_fn(params, rng, data):\n",
    "    x, y = data\n",
    "    logits = model.apply(params, rng, x)\n",
    "    return optax.softmax_cross_entropy_with_integer_labels(logits, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbce4e59-5c90-4823-9a31-0d72a5fbb413",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TrainingConfig(\n",
    "            epochs=25,\n",
    "            )\n",
    "\n",
    "optimizer = optax.adam(0.001)\n",
    "\n",
    "trainer = Trainer(model, optimizer, config)\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "fake_img = jax.numpy.ones((1, 28, 28, 1))\n",
    "init_state = trainer.init(rng, fake_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db111ed-9bcd-4469-8546-b05d41ec5a3c",
   "metadata": {},
   "source": [
    "Let's print out the shapes of our params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e61415-bb94-4f42-a99b-2a4ca1e29604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 379978 parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vi_t/TransformerBlock/MLP/linear': {'b': (256,), 'w': (64, 256)},\n",
       " 'vi_t/TransformerBlock/MLP/linear_1': {'b': (128,), 'w': (256, 128)},\n",
       " 'vi_t/TransformerBlock/MLP/linear_2': {'b': (64,), 'w': (128, 64)},\n",
       " 'vi_t/TransformerBlock/layer_norm': {'offset': (64,), 'scale': (64,)},\n",
       " 'vi_t/TransformerBlock/layer_norm_1': {'offset': (64,), 'scale': (64,)},\n",
       " 'vi_t/TransformerBlock/multi_head_attention/K': {'b': (64,), 'w': (64, 64)},\n",
       " 'vi_t/TransformerBlock/multi_head_attention/Q': {'b': (64,), 'w': (64, 64)},\n",
       " 'vi_t/TransformerBlock/multi_head_attention/V': {'b': (64,), 'w': (64, 64)},\n",
       " 'vi_t/TransformerBlock/multi_head_attention/projection': {'b': (64,),\n",
       "  'w': (64, 64)},\n",
       " 'vi_t/clf': {'b': (10,), 'w': (512, 10)},\n",
       " 'vi_t/hidden_clf': {'b': (512,), 'w': (576, 512)},\n",
       " 'vi_t/patches_encoder/~embed_positions/embed': {'embeddings': (9, 64)},\n",
       " 'vi_t/patches_encoder/~project_patches/linear': {'b': (64,), 'w': (64, 64)}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import prod\n",
    "nb_params = lambda params: jax.tree_util.tree_reduce(lambda a,b: a+b, jax.tree_map(lambda l:prod(l.shape), params))\n",
    "print(f\"The model has {nb_params(init_state.params)} parameters\")\n",
    "jax.tree_map(lambda l:l.shape, init_state.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63172317-20e6-4ac5-b866-6d89fb1ac4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d849c76f2d42fba7da36ace1cc38fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/25 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_state = trainer.train(init_state, loss_fn, x, jit_update_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50061d65-723a-4bb9-b9dc-20bb87e8f532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0.98 on the test set of 10000 observations.\n"
     ]
    }
   ],
   "source": [
    "misclassified = 0\n",
    "n_obs = 0\n",
    "for x, y in x_test:\n",
    "    logits = trainer.apply(trained_state.params, jax.random.PRNGKey(0), x)\n",
    "    predictions = jax.numpy.argmax(jax.nn.softmax(logits, axis=-1), axis=-1)\n",
    "    misclassified += (predictions != y).sum()\n",
    "    n_obs += len(x)\n",
    "print(f\"Accuracy of {1-misclassified/n_obs:.2f} on the test set of {n_obs} observations.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepjax",
   "language": "python",
   "name": "deepjax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
